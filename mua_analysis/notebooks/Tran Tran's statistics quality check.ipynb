{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\elephant\\spade.py:82: UserWarning: fim.so not found in elephant/spade_src folder,you are using the python implementation of fast fca\n",
      "  'you are using the python implementation of fast fca')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from quantities import ns, s\n",
    "from neo.core import SpikeTrain\n",
    "from elephant.statistics import isi, cv, mean_firing_rate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(recording, data_dir, verbose):\n",
    "    if verbose:\n",
    "        print('Loading data:\\t{}'.format(recording))\n",
    "    path = ''.join([os.path.join(data_dir, recording, recording), '.csv'])\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def manipulate_df(df):\n",
    "    df['spike'] = 1\n",
    "    df['time'] = pd.to_timedelta(df['time'], unit='s')\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_time_series(df):\n",
    "    df = df.pivot_table(index='time',\n",
    "                        columns='spike_cluster',\n",
    "                        values='spike',\n",
    "                        aggfunc='count')\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_condition_times(df, experiment):\n",
    "    if experiment == 'DREADD':\n",
    "        max_time = df[df['condition'] == 'CNO']['time'].iloc[-1].total_seconds()\n",
    "        max_time = list(zip(['CNO'], [max_time]))\n",
    "        n_conditions = 1\n",
    "    elif experiment == 'CIT':\n",
    "        max_time_cit = df[df['condition'] == 'CIT']['time'].iloc[-1].total_seconds()\n",
    "        if 'WAY' in df['condition'].values:\n",
    "            max_time_way = df[df['condition'] == 'WAY']['time'].iloc[-1].total_seconds()\n",
    "            n_conditions = 2\n",
    "        else:\n",
    "            max_time_way = max_time_cit\n",
    "            n_conditions = 1\n",
    "        max_time = list(zip(['CIT', 'WAY'], [max_time_cit, max_time_way]))\n",
    "    return max_time, n_conditions\n",
    "\n",
    "\n",
    "def calculate_neuron_cov(col, num_mins_per_bin, total_time):\n",
    "    num_bins = np.int(total_time / num_mins_per_bin)\n",
    "    col_bins = np.array_split(col, num_bins)\n",
    "    cv_isis = pd.Series(np.zeros(num_bins))\n",
    "\n",
    "    for ind, col_bin in enumerate(col_bins):\n",
    "        spike_times = pd.to_numeric(col_bin[col_bin.notnull()].index.values)\n",
    "        try:\n",
    "            spike_train = SpikeTrain(times=spike_times,\n",
    "                                     t_stop=spike_times[-1],\n",
    "                                     units=ns)\n",
    "            plt.tight_layout()\n",
    "            cv_isi = cv(isi(spike_train))\n",
    "        except IndexError:\n",
    "            cv_isi = np.nan\n",
    "        cv_isis[ind] = cv_isi\n",
    "\n",
    "    return cv_isis\n",
    "\n",
    "\n",
    "def calculate_neuron_mfr_elephant(col, num_mins_per_bin, total_time):\n",
    "    num_bins = np.int(total_time / num_mins_per_bin)\n",
    "    col_bins = np.array_split(col, num_bins)\n",
    "    mfrs = pd.Series(np.zeros(num_bins))\n",
    "\n",
    "    for ind, col_bin in enumerate(col_bins):\n",
    "        spike_times = pd.to_numeric(col_bin[col_bin.notnull()].index.values)\n",
    "        try:\n",
    "            spike_train = SpikeTrain(times=spike_times,\n",
    "                                     t_stop=spike_times[-1],\n",
    "                                     units=ns)\n",
    "            mfr = mean_firing_rate(spike_train)\n",
    "        except IndexError:\n",
    "            mfr = np.nan\n",
    "        mfrs[ind] = mfr\n",
    "    mfrs *= 10**9\n",
    "    return mfrs\n",
    "\n",
    "\n",
    "def make_df_stats(averaging_method, recording, cv_isis_ts,mean_firing_rates_ts):\n",
    "    if averaging_method == 'mean':\n",
    "        cov_medians = cv_isis_ts.apply(np.nanmean)\n",
    "        mfr_medians = mean_firing_rates_ts.apply(np.nanmean)\n",
    "\n",
    "    elif averaging_method == 'median':\n",
    "        cov_medians = cv_isis_ts.apply(np.nanmedian)\n",
    "        mfr_medians = mean_firing_rates_ts.apply(np.nanmedian)\n",
    "\n",
    "    elif averaging_method == 'ruairi_old_median':\n",
    "        cov_medians = get_medians(df=cv_isis_ts, lab='CV ISI')\n",
    "        mfr_medians = get_medians(df=mean_firing_rates_ts, lab='Firing Rate')\n",
    "    \n",
    "    df_stats = pd.concat([cov_medians, mfr_medians], axis=1)\n",
    "    df_stats.columns = ['CV ISI', 'Firing Rate']\n",
    "    df_stats['recording'] = recording\n",
    "    return df_stats\n",
    "\n",
    "\n",
    "def calculate_neuron_mfr_numpy(col, num_mins_per_bin, total_time):\n",
    "    num_bins = np.int(total_time / num_mins_per_bin)\n",
    "    col_bins = np.array_split(col, num_bins)\n",
    "    mfrs = pd.Series(np.zeros(num_bins))\n",
    "\n",
    "    for ind, col_bin in enumerate(col_bins):\n",
    "        num_spikes = np.sum(col_bin == 1)\n",
    "        if not num_spikes:\n",
    "            mfr = 0\n",
    "        else:\n",
    "            mfr = num_spikes/(num_mins_per_bin*60)\n",
    "        mfrs[ind] = mfr\n",
    "    mfrs.fillna(0, inplace=True)\n",
    "    #mfrs *= 10**10\n",
    "    return mfrs  #differrent from stats\n",
    "\n",
    "\n",
    "def get_medians(df, lab):\n",
    "    empty = np.zeros(len(df.columns))\n",
    "    for col in range(len(df.columns)):\n",
    "        vals = df.iloc[:, col].dropna().values\n",
    "        med = np.median(vals)\n",
    "        empty[col] = med\n",
    "    df = pd.DataFrame({lab: empty}, index=df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_cluster(dfs, max_time, experiment, df_base, recording, medians, n_conditions, labs=['Firing Rate', 'CV-ISI']):\n",
    "    num_mins = np.int(max_time / 60)\n",
    "\n",
    "    if experiment == 'CIT':\n",
    "        condition_lab_1 = 'Citalopram'\n",
    "        condition_lab_2 = 'WAY'\n",
    "\n",
    "    elif experiment == 'DREADD':\n",
    "        condition_lab_1 = 'CNO'\n",
    "\n",
    "    for col in range(len(dfs[0].columns)):\n",
    "        # New set of plots for each column (for each cluster)\n",
    "        f, a = plt.subplots(figsize=(12, 12), nrows=3)\n",
    "\n",
    "        for ind, df in enumerate(dfs):\n",
    "            # Plot Firing rate and CV ISI over time\n",
    "            x = np.linspace(0, num_mins, len(df))\n",
    "            y = df.iloc[:, col]\n",
    "            a[ind].plot(x, y, linewidth=1.5)\n",
    "\n",
    "            # Plot line for median Firing rate\n",
    "            line_y = np.ones(10) * medians[ind].iloc[col]\n",
    "            line_x = np.linspace(1, num_mins, 10)\n",
    "            a[ind].plot(line_x, line_y, linestyle='--', color='k',\n",
    "                        label='Median {lab}:{num}'.format(lab=labs[ind], num=str(np.round(medians[ind].iloc[col], 2))))\n",
    "\n",
    "            # Set condition indicators\n",
    "            condition_indecator_y = (np.ones(2) * np.max(df.iloc[:, col])) + 1\n",
    "            condition_indecator_x = np.linspace(60, num_mins, 2)\n",
    "            a[ind].plot(condition_indecator_x, condition_indecator_y, linewidth=4, label=(condition_lab_1))\n",
    "\n",
    "            # Indicate WAY if data from CIT experiment\n",
    "            if n_conditions == 2 and experiment == 'CIT':\n",
    "                condition_indecator_x = np.linspace(120, num_mins, 2)\n",
    "                condition_indecator_y = (np.ones(2) * np.max(df.iloc[:, col])) + 0.3\n",
    "                a[ind].plot(condition_indecator_x, condition_indecator_y, linewidth=4, label=(condition_lab_2))\n",
    "\n",
    "            a[ind].set_title('{lab} over time.\\nCluster {clus}'. format(clus=df.columns[col], lab=labs[ind]))\n",
    "\n",
    "            # Set plot aesthetics\n",
    "            a[ind].set_ylabel(labs[ind])\n",
    "            a[ind].set_xlabel('Time [minutes]')\n",
    "            a[ind].fill_between(x, y, alpha=0.4)\n",
    "            a[ind].legend()\n",
    "\n",
    "        if not os.path.exists(fig_folder):\n",
    "            os.mkdir(fig_folder)\n",
    "\n",
    "        spike_times = pd.to_numeric(df_base.iloc[:, col][df_base.iloc[:, col].notnull()].index.values) / 10**10\n",
    "        spike_train = SpikeTrain(times=spike_times,\n",
    "                                 t_stop=spike_times[-1],\n",
    "                                 units=s)\n",
    "        isis = isi(spike_train)\n",
    "        isis = np.array(isis) * 10\n",
    "        a[2].hist(isis, bins=np.int(len(isis) / 4), alpha=0.8)\n",
    "        a[2].set_title('Inter Spike Interval Histogram')\n",
    "        a[2].set_xlim([0, 3.5])\n",
    "        a[2].set_xlabel('Time [Seconds]')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def mkdirs_(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = '2018-05-01_01'\n",
    "data_dir=r'F:\\CIT_WAY\\csvs\\spikes_time_series'\n",
    "experiment='CIT'\n",
    "temp_folder=r'F:\\CIT_WAY\\csvs\\temp'\n",
    "fig_folder=r'F:\\CIT_WAY\\figures\\cluster_over_time_test'\n",
    "mfr_method = 'elephant'\n",
    "averaging_method = 'mean'\n",
    "verbose=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:\t2018-05-01_01\n"
     ]
    }
   ],
   "source": [
    "df = load_data(recording=recording,\n",
    "                       data_dir=data_dir,\n",
    "                       verbose=verbose)\n",
    "df = manipulate_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_times, n_conditions = get_condition_times(df=df, experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_times = max_times[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7897.218067000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:998: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a203fad5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_base = df[df['condition'] == 'Baseline']\n",
    "df_ts = create_time_series(df_base)\n",
    "cv_isis_ts = df_ts.apply(func=calculate_neuron_cov,\n",
    "                                 num_mins_per_bin=2,\n",
    "                                 total_time=60)\n",
    "mean_firing_rates_ts = df_ts.apply(func=calculate_neuron_mfr_elephant,\n",
    "                                           num_mins_per_bin=2,\n",
    "                                           total_time=60)\n",
    "df_stats = make_df_stats(averaging_method='mean', recording=recording, cv_isis_ts=cv_isis_ts, mean_firing_rates_ts=mean_firing_rates_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:998: RuntimeWarning: Mean of empty slice.\n",
      "  return a.std(axis) / a.mean(axis)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c963631128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ts_all = create_time_series(df)\n",
    "cv_isis_ts = df_ts_all.apply(func=calculate_neuron_cov,\n",
    "                                     num_mins_per_bin=2,\n",
    "                                     total_time=np.int(max_times / 60))\n",
    "mean_firing_rates_ts = df_ts_all.apply(func=calculate_neuron_mfr_elephant,\n",
    "                                           num_mins_per_bin=2,\n",
    "                                           total_time=np.int(max_times / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = np.int(np.int(max_times / 60) / 2)\n",
    "col_bins = np.array_split(df_ts_all.loc[:,99], num_bins)\n",
    "mfrs = pd.Series(np.zeros(num_bins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex(['00:00:00.015833', '00:00:00.023667', '00:00:00.023767',\n",
       "                '00:00:00.026600', '00:00:00.048833', '00:00:00.064000',\n",
       "                '00:00:00.091900', '00:00:00.116000', '00:00:00.117467',\n",
       "                '00:00:00.140900',\n",
       "                ...\n",
       "                '02:11:36.378700', '02:11:36.378900', '02:11:36.378933',\n",
       "                '02:11:36.379067', '02:11:36.379300', '02:11:36.379333',\n",
       "                '02:11:36.379633', '02:11:37.217800', '02:11:37.218033',\n",
       "                '02:11:37.218067'],\n",
       "               dtype='timedelta64[ns]', name='time', length=538955, freq=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_all.loc[:,99].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
