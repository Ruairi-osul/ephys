{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import array\n",
    "import mmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data:\t2018-05-03_02 (done)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/sharplab/tran/cat/Tran/2018-05-03_02 (done)/2018-05-03_02.dat\"\n",
    "kilosort_folder = '/Users/sharplab/tran/cat/Tran'\n",
    "recording = '2018-05-03_02 (done)'\n",
    "fig_path = \"/Users/sharplab/tran/cat/Tran/2018-05-03_02 (done)/figures\"\n",
    "data = np.memmap(path, shape =(327354368,32), dtype = np.int16)\n",
    "\n",
    "\n",
    "def load_kilosort_arrays(recording):\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except AssertionError:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(\n",
    "            recording))\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def load_data(recording, kilosort_folder, verbose, sep):\n",
    "    if verbose:\n",
    "        print('\\nLoading Data:\\t{}\\n'.format(recording))\n",
    "        os.chdir(sep.join([kilosort_folder, recording]))\n",
    "        spike_clusters, spike_times, cluster_groups = load_kilosort_arrays(\n",
    "            recording)\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def get_good_cluster_numbers(cluster_groups_df):\n",
    "    good_clusters_df = cluster_groups_df.loc[cluster_groups_df['group'] == 'good', :]\n",
    "    return good_clusters_df['cluster_id'].values\n",
    "\n",
    "spike_clusters, spike_times, cluster_groups = load_data(recording=recording,\n",
    "                                                        kilosort_folder=kilosort_folder,\n",
    "                                                        verbose=True,\n",
    "                                                        sep=sep)\n",
    "\n",
    "good_cluster_numbers = get_good_cluster_numbers(cluster_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_baseline(max_peak_time, from_start_to_max, correct_chan): \n",
    "    mean = np.mean(correct_chan['y_values'].iloc[:21])\n",
    "    std = np.std(correct_chan['y_values'].iloc[:21])\n",
    "    ''' \n",
    "    Baseline is defined as the first point where there's a significant y-value increase. \n",
    "    \n",
    "    aka. the difference in y values between x+1 and x is twice that of x and x-1. x is the data point\n",
    "    '''\n",
    "    \n",
    "    for time_point in from_start_to_max:\n",
    "        if np.absolute(correct_chan.loc[time_point][0]-mean)>3*std:\n",
    "            return time_point-1\n",
    "\n",
    "\n",
    "def find_return_point(min_peak_time, from_min_to_end, correct_chan):\n",
    "    baseline_value = correct_chan.loc[find_baseline(max_peak_time, from_start_to_max, correct_chan)][0]\n",
    "\n",
    "    for return_point in from_min_to_end:\n",
    "        if correct_chan.loc[return_point+1][0] > baseline_value or correct_chan.loc[return_point+1]['trend']=='decrease':\n",
    "            return return_point\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*return_point, np.linspace(-400, 650, 5), 'k')\n",
    "\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan): #Method to find baseline is standardised for all types of waveforms \n",
    "    mean = np.mean(correct_chan['y_values'].iloc[:21])\n",
    "    std = np.std(correct_chan['y_values'].iloc[:21])\n",
    "    \n",
    "    ''' \n",
    "    Same as standard baseline except the value is the first point where there's a significant y-value DECREASE\n",
    "    '''\n",
    "    \n",
    "    for time_point_for_down_up in from_start_to_min:\n",
    "        if np.absolute(correct_chan.loc[time_point_for_down_up][0]-mean)>3*std:\n",
    "            return time_point_for_down_up-1\n",
    "\n",
    "def find_return_point_for_down_up(min_peak_time, from_min_to_end, correct_chan):\n",
    "    baseline_value = correct_chan.loc[find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)][0]\n",
    "    \n",
    "    '''\n",
    "    The time point just before the y-value becoming higher than baseline value (from the min peak)\n",
    "    '''\n",
    "    for return_point_for_down_up in from_min_to_end:\n",
    "        if correct_chan.loc[return_point_for_down_up+1][0] > baseline_value or correct_chan.loc[return_point_for_down_up+1]['trend']=='decrease':\n",
    "            return return_point_for_down_up\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "def plot_waveform_for_down_up(fig_to_save, baseline_for_down_up, correct_chan, baseline_value_for_down_up, return_point_for_down_up):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline_for_down_up, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*return_point_for_down_up, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[return_point_for_down_up][0]-correct_chan.loc[return_point_for_down_up+1][0])/(return_point_for_down_up-(return_point_for_down_up+1))\n",
    "    b = correct_chan.loc[return_point_for_down_up][0]-a*(return_point_for_down_up)\n",
    "\n",
    "    estimated_return_time = (baseline_value_for_down_up-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_special_baseline(small_peak_time, counter_for_special, correct_chan): #Method to find baseline is standardised for all types of waveforms \n",
    "    mean = np.mean(correct_chan['y_values'].iloc[:21])\n",
    "    std = np.std(correct_chan['y_values'].iloc[:21])\n",
    "    ''' \n",
    "    The value is the first point where there's a significant y-value INCREASE before the small max peak\n",
    "    '''\n",
    "    for special_time_point in counter_for_special:\n",
    "        if np.absolute(correct_chan.loc[special_time_point][0]-mean)>3*std: \n",
    "            return special_time_point-1\n",
    "            \n",
    "\n",
    "def find_special_return_point(small_peak_time, from_min_to_end, correct_chan):\n",
    "    special_baseline_value = correct_chan.loc[find_baseline_for_down_up(small_peak_time, from_start_to_min, correct_chan)][0]\n",
    "    \n",
    "    '''\n",
    "    return point is the first value from the min peak, just before the value higher than baseline value\n",
    "    '''\n",
    "    for special_return_point in from_min_to_end:\n",
    "        if correct_chan.loc[special_return_point+1][0] > special_baseline_value or correct_chan.loc[special_return_point+1]['trend']=='decrease':\n",
    "            return special_return_point\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "def plot_special_waveform(fig_to_save, special_baseline, correct_chan, special_baseline_value, special_return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*special_baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*special_return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[special_return_point][0]-correct_chan.loc[special_return_point+1][0])/(special_return_point-(special_return_point+1))\n",
    "    b = correct_chan.loc[special_return_point][0]-a*(special_return_point)\n",
    "\n",
    "    estimated_return_time = (special_baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use label indexing with a null key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-98582b1bd33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_peak_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_start_to_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mbaseline_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mreturn_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_return_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_peak_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_min_to_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         data_table = pd.DataFrame({'Base to max (ms)':(max_peak_time-baseline)/30, \n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1504\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m                     raise TypeError(\"cannot use label indexing with a null \"\n\u001b[0m\u001b[1;32m   1498\u001b[0m                                     \"key\")\n\u001b[1;32m   1499\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use label indexing with a null key"
     ]
    }
   ],
   "source": [
    "num_spikes_for_averaging = 1000\n",
    "num_channels = 32\n",
    "num_samples_per_waveform = 60\n",
    "waveform_window = np.arange(int(-num_samples_per_waveform/2),int(num_samples_per_waveform/2))\n",
    "\n",
    "for cluster_no in np.arange(0,40,1):\n",
    "    cluster_to_plot = good_cluster_numbers[cluster_no]\n",
    "    fig_to_save = [fig_path,\"cluster\"+ str(cluster_to_plot)+'png']\n",
    "    df = pd.DataFrame({'cluster':spike_clusters.flatten(), 'spike_times':spike_times.flatten()})\n",
    "    df = df.loc[df['cluster'].isin(good_cluster_numbers)]\n",
    "    extracted_spikes = df[df['cluster']==cluster_to_plot]['spike_times'][0:num_spikes_for_averaging]\n",
    "    threeD_matrix = np.zeros((num_spikes_for_averaging, num_samples_per_waveform, num_channels)) # Create the 3D matrix witht he shape (1000,60,32)\n",
    "\n",
    "    for spike in np.arange(0,num_spikes_for_averaging):\n",
    "        start_index = int(extracted_spikes.iloc[spike]+waveform_window[0])  #  start of waveform in raw data\n",
    "        end_index = int((extracted_spikes.iloc[spike]+waveform_window[-1])+1)  #  end of waveform in raw data\n",
    "\n",
    "        waveform = data[start_index:end_index, 0:num_channels] #  extract waveform from raw data\n",
    "        threeD_matrix[spike, :, :] = waveform[:,:]  #  add extracted waveform to 3d matrix\n",
    "\n",
    "    mean_waveform = np.mean(threeD_matrix, axis=0)\n",
    "    waveform_per_channel_df = pd.DataFrame(mean_waveform)\n",
    "    maxes = waveform_per_channel_df.apply(np.min, axis=0)\n",
    "    lab = maxes.idxmin()\n",
    "    correct_chan = waveform_per_channel_df.loc[:, lab]\n",
    "    correct_chan = correct_chan.reset_index()\n",
    "    correct_chan.columns = ['figure', 'y_values']\n",
    "    correct_chan.set_index('figure', inplace=True)\n",
    "    new_list = [correct_chan['y_values'][trend_values] for trend_values in np.arange(0,59,1) if (correct_chan['y_values'][trend_values]<correct_chan['y_values'][trend_values+1])]\n",
    "    correct_chan['trend'] = np.where(correct_chan['y_values'].isin(new_list), 'increase', 'decrease')\n",
    "    min_value = correct_chan['y_values'].min()\n",
    "    max_value = correct_chan['y_values'].max()\n",
    "    min_peak_time = correct_chan['y_values'].idxmin()\n",
    "    max_peak_time = correct_chan['y_values'].idxmax()\n",
    "\n",
    "    small_peak_value = correct_chan[:min_peak_time].max()[0]\n",
    "    small_peak_time = correct_chan[:min_peak_time]['y_values'].idxmax()\n",
    "\n",
    "    ''' \n",
    "    Split the data into 3 periods for analysis\n",
    "    1) from start to the max (baseline value is in this period)\n",
    "    2) from max to min (can just index max and min peak time directly)\n",
    "    3) from min to end (return of baseline value is in this period)\n",
    "\n",
    "    In case that there's no min peak, the data is split into\n",
    "    1) from start to max\n",
    "    2) from max to end\n",
    "    '''\n",
    "\n",
    "    from_start_to_max = np.arange(1, max_peak_time+1, 1)\n",
    "    from_start_to_min = np.arange(1, min_peak_time+1, 1)\n",
    "    from_min_to_end = np.arange(min_peak_time, 59, 1) \n",
    "    counter_when_no_min = np.arange(max_peak_time, 59, 1)\n",
    "    counter_for_special = np.arange(1, small_peak_time, 1)\n",
    "    \n",
    "    #Category 1:\n",
    "    if (max_value<60) or (correct_chan[:min_peak_time].max()[0]<60 and correct_chan[min_peak_time:].max()[0]>60):\n",
    "        baseline_for_down_up = find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)\n",
    "        baseline_value_for_down_up= correct_chan.loc[baseline_for_down_up][0]\n",
    "        return_point_for_down_up = find_return_point_for_down_up(min_peak_time, from_min_to_end, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to min (ms)':(min_peak_time-baseline_for_down_up)/30,\n",
    "                                   'Base to max (ms)': np.nan,\n",
    "                                   'Return to base (ms)': (return_point_for_down_up-baseline_for_down_up)/30, \n",
    "                                   'Amplitude base-min (V)': min_value - baseline_value_for_down_up,\n",
    "                                   'Amplitude base-max (V)': np.nan,\n",
    "                                   'Amplitude min-max (V)': np.nan,\n",
    "                                  'spike_category': 'down_up'},\n",
    "                                  index=[0])\n",
    "\n",
    "        plot_waveform_for_down_up(fig_to_save, baseline_for_down_up, correct_chan, baseline_value_for_down_up, return_point_for_down_up)\n",
    "\n",
    "\n",
    "    #Category 2:\n",
    "    elif (max_value)>60 and (min_value>-100):\n",
    "\n",
    "        baseline = find_baseline(max_peak_time, from_start_to_max, correct_chan)\n",
    "        baseline_value = correct_chan.loc[baseline][0]\n",
    "        no_min_return_point = find_return_point_when_no_min(max_peak_time, counter_when_no_min, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to min (ms)': np.nan,\n",
    "                                   'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                                   'Return to base (ms)': (no_min_return_point-baseline)/30, \n",
    "                                   'Amplitude base-min (V)': np.nan,\n",
    "                                   'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                                   'Amplitude min-max (V)': np.nan,\n",
    "                                  'spike_category': 'just_up'}, index=[0])\n",
    "\n",
    "        plot_waveform_when_no_min(fig_to_save, baseline, correct_chan, baseline_value, no_min_return_point)\n",
    "\n",
    "    #Category 3:    \n",
    "    elif (correct_chan[:min_peak_time].max()[0])>60 and (correct_chan[min_peak_time:].max()[0]>60) and (correct_chan[:min_peak_time].max()[0]<correct_chan[min_peak_time:].max()[0]):\n",
    "        special_baseline = find_special_baseline(small_peak_time, counter_for_special, correct_chan)\n",
    "        special_baseline_value = correct_chan.loc[special_baseline][0]\n",
    "        special_return_point = find_special_return_point(small_peak_time, from_min_to_end, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to min (ms)':(min_peak_time-special_baseline)/30, \n",
    "                                   'Base to max (ms)': np.nan,\n",
    "                                   'Return to base (ms)': (special_return_point-special_baseline)/30, \n",
    "                                   'Amplitude base-min (V)': min_value - special_baseline_value,\n",
    "                                   'Amplitude base-max (V)': small_peak_value - special_baseline_value,\n",
    "                                   'Amplitude min-max (V)':small_peak_value + np.absolute(min_value),\n",
    "                                  'spike_category': 'up_down_up'},\n",
    "                                  index=[0])\n",
    "        plot_special_waveform(fig_to_save, special_baseline, correct_chan, special_baseline_value, special_return_point)\n",
    "\n",
    "    #Category 4:  \n",
    "    else:\n",
    "\n",
    "        baseline = find_baseline(max_peak_time, from_start_to_max, correct_chan)\n",
    "        baseline_value = correct_chan.loc[baseline][0]\n",
    "        return_point = find_return_point(min_peak_time, from_min_to_end, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                                   'Base to min (ms)':(min_peak_time-baseline)/30, \n",
    "                                   'Return to base (ms)':(return_point-baseline)/30, \n",
    "                                   'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                                   'Amplitude min-max (V)':max_value + np.absolute(min_value),\n",
    "                                  'spike_category': 'up_down_up'}, index=[0])\n",
    "\n",
    "        plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan['y_values'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_chan['y_values'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.absolute(correct_chan.loc[15][0]-correct_chan.loc[14][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
