{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import array\n",
    "import mmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data:\t2018-05-03_02 (done)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/sharplab/tran/cat/Tran/2018-05-03_02 (done)/2018-05-03_02.dat\"\n",
    "kilosort_folder = '/Users/sharplab/tran/cat/Tran'\n",
    "recording = '2018-05-03_02 (done)'\n",
    "fig_path = \"/Users/sharplab/tran/cat/Tran/2018-05-03_02 (done)/figures\"\n",
    "data = np.memmap(path, shape =(327354368,32), dtype = np.int16)\n",
    "\n",
    "\n",
    "def load_kilosort_arrays(recording):\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except AssertionError:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(\n",
    "            recording))\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def load_data(recording, kilosort_folder, verbose, sep):\n",
    "    if verbose:\n",
    "        print('\\nLoading Data:\\t{}\\n'.format(recording))\n",
    "        os.chdir(sep.join([kilosort_folder, recording]))\n",
    "        spike_clusters, spike_times, cluster_groups = load_kilosort_arrays(\n",
    "            recording)\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def get_good_cluster_numbers(cluster_groups_df):\n",
    "    good_clusters_df = cluster_groups_df.loc[cluster_groups_df['group'] == 'good', :]\n",
    "    return good_clusters_df['cluster_id'].values\n",
    "\n",
    "spike_clusters, spike_times, cluster_groups = load_data(recording=recording,\n",
    "                                                        kilosort_folder=kilosort_folder,\n",
    "                                                        verbose=True,\n",
    "                                                        sep=sep)\n",
    "\n",
    "good_cluster_numbers = get_good_cluster_numbers(cluster_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_baseline(max_peak_time, from_start_to_max, correct_chan): #Method to find baseline is standardised for all types of waveforms \n",
    "    baseline = []\n",
    "    \n",
    "    ''' \n",
    "    Baseline is defined as the the last value, from start to max period, that is smaller than 10% of peak value \n",
    "    '''\n",
    "    \n",
    "    for time_point in from_start_to_max:\n",
    "        if np.absolute(correct_chan.loc[time_point+1][0]-correct_chan.loc[time_point][0])>correct_chan.loc[time_point][0]:\n",
    "            return time_point\n",
    "\n",
    "\n",
    "def find_return_point(min_peak_time, from_min_to_end, correct_chan):\n",
    "    return_point = []\n",
    "    baseline_value = correct_chan.loc[find_baseline(max_peak_time, from_start_to_max, correct_chan)][0]\n",
    "    \n",
    "    '''\n",
    "    return point is the first value just before the value higher than baseline value\n",
    "    '''\n",
    "    for return_time_point in from_min_to_end:\n",
    "        if correct_chan.loc[return_time_point+1][0] > baseline_value:\n",
    "            return return_time_point\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Find the estimation of the return to baseline value if the return point is not very accurate due to not having enough data points\n",
    "    \n",
    "    y=ax+b\n",
    "    \n",
    "    where y is our y value x is time\n",
    "    \n",
    "    we can find the values of a and b by solving the simultaneous equation using the x and y values of the two data points above and below:\n",
    "\n",
    "    y1 = ax1 + b \n",
    "    y2 = ax2 + b \n",
    "\n",
    "    => a = (x1-x2)/(y1-y2)\n",
    "   \n",
    "       b = y1-ax1\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    a = (correct_chan.loc[return_point][0]-correct_chan.loc[return_point+1][0])/(return_point-(return_point+1))\n",
    "    b = correct_chan.loc[return_point][0]-a*(return_point)\n",
    "\n",
    "    estimated_return_time = (baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "    plt.close()\n",
    "\n",
    "def find_return_point_when_no_min(max_peak_time, counter_when_no_min, correct_chan):\n",
    "    return_point_when_no_min = []\n",
    "    base_value = correct_chan.loc[find_baseline(max_peak_time, from_start_to_max, correct_chan)[-1]][0]\n",
    "    \n",
    "    '''\n",
    "    Same as the previous method except being value just before the value lower than baseline value\n",
    "    '''\n",
    "  \n",
    "    for no_min_return_point in counter_when_no_min:\n",
    "        if correct_chan.loc[no_min_return_point+1][0] < baseline_value:\n",
    "            return no_min_return_point\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def plot_waveform_when_no_min(fig_to_save, baseline, correct_chan, baseline_value, no_min_return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*no_min_return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[no_min_return_point][0]-correct_chan.loc[no_min_return_point+1][0])/(no_min_return_point-(no_min_return_point+1))\n",
    "    b = correct_chan.loc[no_min_return_point][0]-a*(no_min_return_point)\n",
    "\n",
    "    estimated_return_time = (baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "    plt.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_baseline_for_down_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b1d217b1e12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbaseline_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbaseline_value\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbaseline_value\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_peak_time\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmin_peak_time\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mspecial_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_baseline_for_down_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_peak_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_start_to_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mspecial_baseline_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecial_baseline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mspecial_return_time_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_return_point_for_down_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_peak_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_min_to_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_chan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_baseline_for_down_up' is not defined"
     ]
    }
   ],
   "source": [
    "num_spikes_for_averaging = 1000\n",
    "num_channels = 32\n",
    "num_samples_per_waveform = 60\n",
    "waveform_window = np.arange(int(-num_samples_per_waveform/2),int(num_samples_per_waveform/2))\n",
    "\n",
    "\n",
    "for cluster_no in np.arange(0,41,1):\n",
    "    cluster_to_plot = good_cluster_numbers[cluster_no]\n",
    "    fig_to_save = [fig_path,\"cluster\"+ str(cluster_to_plot)+'png']\n",
    "    df = pd.DataFrame({'cluster':spike_clusters.flatten(), 'spike_times':spike_times.flatten()})\n",
    "    df = df.loc[df['cluster'].isin(good_cluster_numbers)]\n",
    "    extracted_spikes = df[df['cluster']==cluster_to_plot]['spike_times'][0:num_spikes_for_averaging]\n",
    "    threeD_matrix = np.zeros((num_spikes_for_averaging, num_samples_per_waveform, num_channels)) # Create the 3D matrix witht he shape (1000,60,32)\n",
    "\n",
    "    for spike in np.arange(0,num_spikes_for_averaging):\n",
    "        start_index = int(extracted_spikes.iloc[spike]+waveform_window[0])  #  start of waveform in raw data\n",
    "        end_index = int((extracted_spikes.iloc[spike]+waveform_window[-1])+1)  #  end of waveform in raw data\n",
    "\n",
    "        waveform = data[start_index:end_index, 0:num_channels] #  extract waveform from raw data\n",
    "        threeD_matrix[spike, :, :] = waveform[:,:]  #  add extracted waveform to 3d matrix\n",
    "\n",
    "    mean_waveform = np.mean(threeD_matrix, axis=0)\n",
    "    waveform_per_channel_df = pd.DataFrame(mean_waveform)\n",
    "    maxes = waveform_per_channel_df.apply(np.min, axis=0)\n",
    "    lab = maxes.idxmin()\n",
    "    correct_chan = waveform_per_channel_df.loc[:, lab]\n",
    "    correct_chan = correct_chan.reset_index()\n",
    "    correct_chan.columns = ['figure', 'y_values']\n",
    "    correct_chan.set_index('figure', inplace=True)\n",
    "    new_list = [correct_chan['y_values'][trend_values] for trend_values in np.arange(0,59,1) if (correct_chan['y_values'][trend_values]<correct_chan['y_values'][trend_values+1])]\n",
    "    correct_chan['trend'] = np.where(correct_chan['y_values'].isin(new_list), 'increase', 'decrease')\n",
    "    min_value = correct_chan['y_values'].min()\n",
    "    max_value = correct_chan['y_values'].max()\n",
    "    min_peak_time = correct_chan['y_values'].idxmin()\n",
    "    max_peak_time = correct_chan['y_values'].idxmax()\n",
    "\n",
    "    ''' \n",
    "    Split the data into 3 periods for analysis\n",
    "    1) from start to the max (baseline value is in this period)\n",
    "    2) from max to min (can just index max and min peak time directly)\n",
    "    3) from min to end (return of baseline value is in this period)\n",
    "\n",
    "    In case that there's no min peak, the data is split into\n",
    "    1) from start to max\n",
    "    2) from max to end\n",
    "    '''\n",
    "\n",
    "    from_start_to_max = np.arange(1, max_peak_time-1, 1)\n",
    "    from_min_to_end = np.arange(min_peak_time, 60, 1) \n",
    "    from_start_to_min = np.arange(1, min_peak_time-1, 1)\n",
    "    counter_when_no_min = np.arange(max_peak_time, 59, 1)\n",
    "    \n",
    "    baseline = find_baseline(max_peak_time, from_start_to_max, correct_chan)\n",
    "    baseline_value = correct_chan.loc[baseline][0]\n",
    "    if (max_value-baseline_value<50) or (max_value-baseline_value>50 and max_peak_time>min_peak_time and min_value<-100):\n",
    "        special_baseline = find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)\n",
    "        special_baseline_value = correct_chan.loc[special_baseline][0]\n",
    "        special_return_time_point = find_return_point_for_down_up(min_peak_time, from_min_to_end, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to min (ms)':(min_peak_time-baseline)/30, \n",
    "                                   'Return to base (ms)': (return_point-baseline)/30, \n",
    "                                   'Amplitude base-min (V)': min_value - baseline_value,\n",
    "                                  'spike_category': 'down_up'},\n",
    "                                  index=[0])\n",
    "\n",
    "        plot_waveform_for_down_up(fig_to_save, special_baseline, correct_chan, special_baseline_value, special_return_time_point)\n",
    "\n",
    "    elif (max_value-baseline_value)>50 and (min_value>-100):\n",
    "        no_min_return_point = find_return_point_when_no_min(max_peak_time, counter_when_no_min, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                                   'Return to base (ms)': (no_min_return_point-baseline)/30, \n",
    "                                   'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                                  'spike_category': 'just_up'}, index=[0])\n",
    "\n",
    "        plot_waveform_when_no_min(fig_to_save, baseline, correct_chan, baseline_value, no_min_return_point)\n",
    "\n",
    "    else:\n",
    "        return_point = find_return_point(min_peak_time, from_min_to_end, correct_chan)\n",
    "        data_table = pd.DataFrame({'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                                   'Base to min (ms)':(min_peak_time-baseline)/30, \n",
    "                                   'Return to base (ms)':(return_point-baseline)/30, \n",
    "                                   'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                                   'Amplitude min-max (V)':max_value - min_value,\n",
    "                                  'spike_category': 'up_down_up'}, index=[0])\n",
    "\n",
    "        plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
