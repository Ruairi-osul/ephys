{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilosort_folder = r'C:\\Users\\Rory\\raw_data\\CIT_WAY\\dat_files\\cat'\n",
    "recording = r'2018-05-01_01'\n",
    "sep = '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_kilosort_arrays(recording):\n",
    "    '''\n",
    "    Loads arrays generated during kilosort into numpy arrays and pandas DataFrames\n",
    "    Parameters:\n",
    "        recording       = name of the recording being analysed\n",
    "    Returns:\n",
    "        spike_clusters  = numpy array of len(num_spikes) identifying the cluster from which each spike arrose\n",
    "        spike_times     = numpy array of len(num_spikes) identifying the time in samples at which each spike occured\n",
    "        cluster_groups  = pandas DataDrame with one row per cluster and column 'cluster_group' identifying whether\n",
    "                          that cluster had been marked as 'Noise', 'MUA' or 'Good'\n",
    "    '''\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except AssertionError:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(\n",
    "            recording))\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "\n",
    "def load_data(recording, kilosort_folder, verbose, sep):\n",
    "    '''\n",
    "    Loads arrays generated during kilosort into numpy arrays and pandas DataFrames\n",
    "    Parameters:\n",
    "        recording       = name of the recording being analysed\n",
    "        kilosort_folder = the name of the root directory in which subdirectories for each recording are stored\n",
    "                          inside the sub-directories should be the files generated during spike sorting with\n",
    "                          kilosort and phy\n",
    "        verbose         = True or False\n",
    "        sep             = os directory delimeter e.g. '/'\n",
    "    Returns:\n",
    "        spike_clusters  = numpy array of len(num_spikes) identifying the cluster from which each spike arrose\n",
    "        spike_times     = numpy array of len(num_spikes) identifying the time in samples at which each spike occured\n",
    "        cluster_groups  = pandas DataDrame with one row per cluster and column\n",
    "                          'cluster_group' identifying whetherthat cluster had been marked as 'Noise', 'MUA' or 'Good'\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('\\nLoading Data:\\t{}\\n'.format(recording))\n",
    "    os.chdir(sep.join([kilosort_folder, recording]))\n",
    "    spike_clusters, spike_times, cluster_groups = load_kilosort_arrays(\n",
    "        recording)\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "\n",
    "def get_good_cluster_numbers(cluster_groups_df):\n",
    "    '''\n",
    "    Takes the cluster_groups pandas DataFrame fomed during data loading and returns a numpy array of cluster\n",
    "    ids defined as 'Good' during kilosort and phy spike sorting\n",
    "    Parameters:\n",
    "        cluster_groups_df   = the pandas DataFrame containing information on which cluster is 'Good', 'Noise' etc.\n",
    "    Returns:\n",
    "        A numpy array of 'Good' cluster ids\n",
    "    '''\n",
    "    good_clusters_df = cluster_groups_df.loc[cluster_groups_df['group'] == 'good', :]\n",
    "    return good_clusters_df['cluster_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data:\t2018-05-01_01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spike_clusters, spike_times, cluster_groups = load_data(recording=recording,\n",
    "                                                        kilosort_folder=kilosort_folder,\n",
    "                                                        verbose=True,\n",
    "                                                        sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cluster_numbers = get_good_cluster_numbers(cluster_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times_0 = spike_times[spike_clusters==good_cluster_numbers[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_st = spike_times[:10000]\n",
    "num_waveforms_toload = len(extract_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 32\n",
    "samples_around_spike = np.arange(-60, 60)\n",
    "num_waveform_samples = len(samples_around_spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_template = np.zeros((num_waveforms_toload +1,\n",
    "                         num_channels,\n",
    "                         num_waveform_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.memmap('2018-05-01_01.dat', dtype='int64')\n",
    "total_len = len(temp)\n",
    "real_len = int(total_len/num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmf = np.memmap('2018-05-01_01.dat', dtype='int64', shape=(32, real_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for spike, ind in enumerate(range(num_waveforms_toload)):\n",
    "    temp_wf = mmf[:, int(extract_st[spike]+samples_around_spike[0]):int(extract_st[spike]+samples_around_spike[-1]+1)]\n",
    "    empty_template[ind, :, :] = temp_wf[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-533951a5fff0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_template\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(empty_template[6, 7, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(empty_template, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "f, a = plt.subplots(nrows=16, ncols=2, figsize=(15,15))\n",
    "for chan in range(means.shape[0]):\n",
    "    if chan >= 16:\n",
    "        col = 1\n",
    "        chan -= 16\n",
    "    else:\n",
    "        col = 0\n",
    "    a[chan, col].plot(np.arange(-60, 60)/30, means[chan, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.fromfile(recording + '.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984.7253333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]/32/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1905336320 into shape (31,59541760)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e13dc62d0895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1905336320 into shape (31,59541760)"
     ]
    }
   ],
   "source": [
    "reshaped = data.reshape(31, int(data.shape[0]/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.07875555555555"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped.shape[1]/30000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 59541760)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
