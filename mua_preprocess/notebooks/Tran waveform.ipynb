{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import array\n",
    "import mmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sep = '/'\n",
    "import math\n",
    "import scipy.linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data:\t2018-04-12_371b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/sharplab/tran/cat/Tran/2018-04-12_371b/2018-04-12_371b.dat\"\n",
    "kilosort_folder = '/Users/sharplab/tran/cat/Tran'\n",
    "recording = '2018-04-12_371b'\n",
    "fig_path = \"/Users/sharplab/tran/cat/Tran/2018-04-12_371b/figures\"\n",
    "data = np.memmap(path, shape =(241320960,32), dtype = np.int16)\n",
    "\n",
    "\n",
    "def load_kilosort_arrays(recording):\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except AssertionError:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(\n",
    "            recording))\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def load_data(recording, kilosort_folder, verbose, sep):\n",
    "    if verbose:\n",
    "        print('\\nLoading Data:\\t{}\\n'.format(recording))\n",
    "        os.chdir(sep.join([kilosort_folder, recording]))\n",
    "        spike_clusters, spike_times, cluster_groups = load_kilosort_arrays(\n",
    "            recording)\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "def get_good_cluster_numbers(cluster_groups_df):\n",
    "    good_clusters_df = cluster_groups_df.loc[cluster_groups_df['group'] == 'good', :]\n",
    "    return good_clusters_df['cluster_id'].values\n",
    "\n",
    "spike_clusters, spike_times, cluster_groups = load_data(recording=recording,\n",
    "                                                        kilosort_folder=kilosort_folder,\n",
    "                                                        verbose=True,\n",
    "                                                        sep=sep)\n",
    "\n",
    "good_cluster_numbers = get_good_cluster_numbers(cluster_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_cluster_numbers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_plot = good_cluster_numbers[1]\n",
    "num_spikes_for_averaging = 2000\n",
    "num_channels = 32\n",
    "num_samples_per_waveform = 60\n",
    "waveform_window = np.arange(int(-num_samples_per_waveform/2),int(num_samples_per_waveform/2))\n",
    "fig_to_save = [fig_path,\"cluster\"+ str(cluster_to_plot)+'png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the spikes for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'cluster':spike_clusters.flatten(), 'spike_times':spike_times.flatten()})\n",
    "df = df.loc[df['cluster'].isin(good_cluster_numbers)]\n",
    "extracted_spikes = df[df['cluster']==cluster_to_plot]['spike_times'][0:num_spikes_for_averaging]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the mean waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeD_matrix = np.zeros((num_spikes_for_averaging, num_samples_per_waveform, num_channels)) # Create the 3D matrix witht he shape (1000,60,32)\n",
    "\n",
    "for spike in np.arange(0,num_spikes_for_averaging):\n",
    "    start_index = int(extracted_spikes.iloc[spike]+waveform_window[0])  #  start of waveform in raw data\n",
    "    end_index = int((extracted_spikes.iloc[spike]+waveform_window[-1])+1)  #  end of waveform in raw data\n",
    "    \n",
    "    waveform = data[start_index:end_index, 0:num_channels] #  extract waveform from raw data\n",
    "    threeD_matrix[spike, :, :] = waveform[:,:]  #  add extracted waveform to 3d matrix\n",
    "\n",
    "mean_waveform = np.mean(threeD_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index out the largest waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_per_channel_df = pd.DataFrame(mean_waveform)\n",
    "maxes = waveform_per_channel_df.apply(np.min, axis=0)\n",
    "lab = maxes.idxmin()\n",
    "lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "correct_chan = waveform_per_channel_df.loc[:, lab]\n",
    "plt.plot(correct_chan, linestyle=None, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan = correct_chan.reset_index()\n",
    "correct_chan.columns = ['figure', 'y_values']\n",
    "correct_chan.set_index('figure', inplace=True)\n",
    "new_list = [correct_chan['y_values'][trend_values] for trend_values in np.arange(0,59,1) if (correct_chan['y_values'][trend_values]<correct_chan['y_values'][trend_values+1])]\n",
    "correct_chan['trend'] = np.where(correct_chan['y_values'].isin(new_list), 'increase', 'decrease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into different time periods for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = correct_chan['y_values'].min()\n",
    "max_value = correct_chan['y_values'].max()\n",
    "min_peak_time = correct_chan['y_values'].idxmin()\n",
    "max_peak_time = correct_chan['y_values'].idxmax()\n",
    "\n",
    "small_peak_value = correct_chan[:min_peak_time].max()[0]\n",
    "small_peak_time = correct_chan[:min_peak_time]['y_values'].idxmax()\n",
    "\n",
    "''' \n",
    "Split the data into 3 periods for analysis\n",
    "1) from start to the max (baseline value is in this period)\n",
    "2) from max to min (can just index max and min peak time directly)\n",
    "3) from min to end (return of baseline value is in this period)\n",
    "\n",
    "In case that there's no min peak, the data is split into\n",
    "1) from start to max\n",
    "2) from max to end\n",
    "'''\n",
    "\n",
    "from_start_to_max = np.arange(1, max_peak_time+1, 1)\n",
    "from_start_to_min = np.arange(1, correct_chan['y_values'].idxmin()+1, 1)\n",
    "from_min_to_end = np.arange(min_peak_time, 59, 1) \n",
    "counter_when_no_min = np.arange(max_peak_time, 59, 1)\n",
    "counter_for_special = np.arange(1, small_peak_time, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for standard waveforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_baseline(max_peak_time, from_start_to_max, correct_chan): \n",
    "    baseline = []\n",
    "    ''' \n",
    "    Baseline is defined as the first point where there's a significant y-value increase. \n",
    "    \n",
    "    aka. the difference in y values between x+1 and x is twice that of x and x-1. x is the data point\n",
    "    '''\n",
    "    \n",
    "    for time_point in from_start_to_max:\n",
    "        if np.absolute(correct_chan.loc[time_point][0]-correct_chan.loc[time_point-1][0])*3>np.absolute(correct_chan.loc[time_point+1][0]-correct_chan.loc[time_point][0])>np.absolute(correct_chan.loc[time_point][0]-correct_chan.loc[time_point-1][0]): \n",
    "            baseline.append(time_point)\n",
    "        else:\n",
    "            pass\n",
    "    return baseline\n",
    "\n",
    "\n",
    "def find_return_point(min_peak_time, from_min_to_end, correct_chan):\n",
    "    return_point = []\n",
    "    baseline_value = correct_chan.loc[find_baseline(max_peak_time, from_start_to_max, correct_chan)[-1]][0]\n",
    "    \n",
    "    '''\n",
    "    return point is the first value just before the value becoming higher than baseline value\n",
    "    '''\n",
    "    for return_time_point in from_min_to_end:\n",
    "        if correct_chan.loc[return_time_point+1][0] > baseline_value or correct_chan.loc[return_time_point+1]['trend']=='decrease':\n",
    "            return return_time_point\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Find the estimation of the return to baseline value if the return point is not very accurate due to not having enough data points\n",
    "    \n",
    "    y=ax+b\n",
    "    \n",
    "    where y is our y value x is time\n",
    "    \n",
    "    we can find the values of a and b by solving the simultaneous equation using the x and y values of the two data points above and below:\n",
    "\n",
    "    y1 = ax1 + b \n",
    "    y2 = ax2 + b \n",
    "\n",
    "    => a = (x1-x2)/(y1-y2)\n",
    "   \n",
    "       b = y1-ax1\n",
    "           a = (correct_chan.loc[return_point][0]-correct_chan.loc[return_point+1][0])/(return_point-(return_point+1))\n",
    "    b = correct_chan.loc[return_point][0]-a*(return_point)\n",
    "\n",
    "    estimated_return_time = (baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    '''\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    plt.savefig(sep.join(fig_to_save))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for waveforms without trough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_return_point_when_no_min(max_peak_time, counter_when_no_min, correct_chan):\n",
    "    return_point_when_no_min = []\n",
    "    base_value = correct_chan.loc[find_baseline(max_peak_time, from_start_to_max, correct_chan)[-1]][0]\n",
    "    \n",
    "    '''\n",
    "    The time point just before the y-value becoming lower than baseline value (from the max peak)\n",
    "    '''\n",
    "  \n",
    "    for no_min_return_point in counter_when_no_min:\n",
    "        if correct_chan.loc[no_min_return_point+1][0] < baseline_value:\n",
    "            return no_min_return_point\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def plot_waveform_when_no_min(fig_to_save, baseline, correct_chan, baseline_value, no_min_return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*no_min_return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[no_min_return_point][0]-correct_chan.loc[no_min_return_point+1][0])/(no_min_return_point-(no_min_return_point+1))\n",
    "    b = correct_chan.loc[no_min_return_point][0]-a*(no_min_return_point)\n",
    "\n",
    "    estimated_return_time = (baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for down_up waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan): #Method to find baseline is standardised for all types of waveforms \n",
    "    mean = np.mean(correct_chan['y_values'].iloc[:11])\n",
    "    std = np.std(correct_chan['y_values'].iloc[:11])\n",
    "    \n",
    "    ''' \n",
    "    Same as standard baseline except the value is the first point where there's a significant y-value DECREASE\n",
    "    '''\n",
    "    \n",
    "    for time_point_for_down_up in from_start_to_min:\n",
    "        if np.absolute(correct_chan.loc[time_point_for_down_up][0]-mean)>3*std:\n",
    "            return time_point_for_down_up-1\n",
    "\n",
    "def find_return_point_for_down_up(min_peak_time, from_min_to_end, correct_chan):\n",
    "    baseline_value = correct_chan.loc[find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)][0]\n",
    "    \n",
    "    '''\n",
    "    The time point just before the y-value becoming higher than baseline value (from the min peak)\n",
    "    '''\n",
    "    for return_point_for_down_up in from_min_to_end:\n",
    "        if correct_chan.loc[return_point_for_down_up+1][0] > baseline_value or correct_chan.loc[return_point_for_down_up+1]['trend']=='decrease':\n",
    "            return return_point_for_down_up\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "def plot_waveform_for_down_up(fig_to_save, baseline_for_down_up, correct_chan, baseline_value_for_down_up, return_point_for_down_up):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*baseline_for_down_up, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*return_point_for_down_up, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[return_point_for_down_up][0]-correct_chan.loc[return_point_for_down_up+1][0])/(return_point_for_down_up-(return_point_for_down_up+1))\n",
    "    b = correct_chan.loc[return_point_for_down_up][0]-a*(return_point_for_down_up)\n",
    "\n",
    "    estimated_return_time = (baseline_value_for_down_up-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for special up-down-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_special_baseline(small_peak_time, counter_for_special, correct_chan): #Method to find baseline is standardised for all types of waveforms \n",
    "    special_baseline = []\n",
    "\n",
    "    ''' \n",
    "    The value is the first point where there's a significant y-value INCREASE before the small max peak\n",
    "    '''\n",
    "    for special_time_point in counter_for_special:\n",
    "        if np.absolute(correct_chan.loc[special_time_point][0]-correct_chan.loc[special_time_point-1][0])*3>np.absolute(correct_chan.loc[special_time_point+1][0]-correct_chan.loc[special_time_point][0])>np.absolute(correct_chan.loc[special_time_point][0]-correct_chan.loc[special_time_point-1][0]): \n",
    "            special_baseline.append(special_time_point)\n",
    "        else:\n",
    "            pass\n",
    "    return special_baseline\n",
    "\n",
    "def find_special_return_point(small_peak_time, from_min_to_end, correct_chan):\n",
    "    special_baseline_value = correct_chan.loc[find_baseline_for_down_up(small_peak_time, from_start_to_min, correct_chan)[-1]][0]\n",
    "    \n",
    "    '''\n",
    "    return point is the first value from the min peak, just before the value higher than baseline value\n",
    "    '''\n",
    "    for special_return_point in from_min_to_end:\n",
    "        if correct_chan.loc[special_return_point+1][0] > special_baseline_value or correct_chan.loc[special_return_point+1]['trend']=='decrease':\n",
    "            return special_return_point\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "def plot_special_waveform(fig_to_save, special_baseline, correct_chan, special_baseline_value, special_return_point):\n",
    "    plt.plot(correct_chan['y_values'], linestyle=None, marker='.')\n",
    "    plt.plot(np.ones(5)*special_baseline, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*special_return_point, np.linspace(-400, 650, 5), 'k')\n",
    "    plt.plot(np.ones(5)*min_peak_time, np.linspace(-400, 650, 5), 'k')\n",
    "    \n",
    "    a = (correct_chan.loc[special_return_point][0]-correct_chan.loc[special_return_point+1][0])/(special_return_point-(special_return_point+1))\n",
    "    b = correct_chan.loc[special_return_point][0]-a*(special_return_point)\n",
    "\n",
    "    estimated_return_time = (special_baseline_value-b)/a\n",
    "    plt.plot(np.ones(5)*estimated_return_time, np.linspace(-400, 650, 5), 'r')\n",
    "    plt.savefig(sep.join(fig_to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "3 categories: 1) if there's no max peak (max value <50) or \n",
    "                    \n",
    "                    the first max before min is <50 and the first max after min is >50\n",
    "                    \n",
    "              2) if there's a max value (max > 50) but no min value (min>-50). \n",
    "              \n",
    "              3) if both peaks before and after min are >50, and the peak after min is bigger than the peak before min.\n",
    "              \n",
    "              4) normal up-down-up plot\n",
    "'''\n",
    "\n",
    "#Category 1:\n",
    "if (max_value<50) or (correct_chan[:min_peak_time].max()[0]<50 and correct_chan[min_peak_time:].max()[0]>50):\n",
    "    baseline_for_down_up = find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)\n",
    "    baseline_value_for_down_up= correct_chan.loc[baseline_for_down_up][0]\n",
    "    return_point_for_down_up = find_return_point_for_down_up(min_peak_time, from_min_to_end, correct_chan)\n",
    "    data_table = pd.DataFrame({'Base to min (ms)':(min_peak_time-baseline_for_down_up)/30,\n",
    "                               'Base to max (ms)': np.nan,\n",
    "                               'Return to base (ms)': (return_point_for_down_up-baseline_for_down_up)/30, \n",
    "                               'Amplitude base-min (V)': min_value - baseline_value_for_down_up,\n",
    "                               'Amplitude base-max (V)': np.nan,\n",
    "                               'Amplitude min-max (V)': np.nan,\n",
    "                              'spike_category': 'down_up'},\n",
    "                              index=[0])\n",
    "    \n",
    "    plot_waveform_for_down_up(fig_to_save, baseline_for_down_up, correct_chan, baseline_value_for_down_up, return_point_for_down_up)\n",
    "\n",
    "    \n",
    "#Category 2:\n",
    "elif (max_value)>50 and (min_value>-100):\n",
    "    \n",
    "    baseline = baseline_algo(y=correct_chan['y_values'], lag=5, threshold=3.5, influence=0.3)\n",
    "    baseline_value = correct_chan.loc[baseline][0]\n",
    "    no_min_return_point = find_return_point_when_no_min(max_peak_time, counter_when_no_min, correct_chan)\n",
    "    data_table = pd.DataFrame({'Base to min (ms)': np.nan,\n",
    "                               'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                               'Return to base (ms)': (no_min_return_point-baseline)/30, \n",
    "                               'Amplitude base-min (V)': np.nan,\n",
    "                               'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                               'Amplitude min-max (V)': np.nan,\n",
    "                              'spike_category': 'just_up'}, index=[0])\n",
    "    \n",
    "    plot_waveform_when_no_min(fig_to_save, baseline, correct_chan, baseline_value, no_min_return_point)\n",
    "\n",
    "#Category 3:    \n",
    "elif (correct_chan[:min_peak_time].max()[0])>50 and (correct_chan[min_peak_time:].max()[0]>50) and (correct_chan[:min_peak_time].max()[0]<correct_chan[min_peak_time:].max()[0]):\n",
    "    special_baseline = baseline_algo(y=correct_chan['y_values'], lag=5, threshold=3.5, influence=0.3)\n",
    "    special_baseline_value = correct_chan.loc[special_baseline][0]\n",
    "    special_return_point = find_special_return_point(small_peak_time, from_min_to_end, correct_chan)\n",
    "    data_table = pd.DataFrame({'Base to min (ms)':(min_peak_time-special_baseline)/30, \n",
    "                               'Base to max (ms)': np.nan,\n",
    "                               'Return to base (ms)': (special_return_point-special_baseline)/30, \n",
    "                               'Amplitude base-min (V)': min_value - special_baseline_value,\n",
    "                               'Amplitude base-max (V)': small_peak_value - special_baseline_value,\n",
    "                               'Amplitude min-max (V)':small_peak_value + np.absolute(min_value),\n",
    "                              'spike_category': 'up_down_up'},\n",
    "                              index=[0])\n",
    "    plot_special_waveform(fig_to_save, special_baseline, correct_chan, special_baseline_value, special_return_point)\n",
    "\n",
    "#Category 4:  \n",
    "else:\n",
    "\n",
    "    baseline = baseline_algo(y=correct_chan['y_values'], lag=5, threshold=3.5, influence=0.3)\n",
    "    baseline_value = correct_chan.loc[baseline][0]\n",
    "    return_point = find_return_point(min_peak_time, from_min_to_end, correct_chan)\n",
    "    data_table = pd.DataFrame({'Base to max (ms)':(max_peak_time-baseline)/30, \n",
    "                               'Base to min (ms)':(min_peak_time-baseline)/30, \n",
    "                               'Return to base (ms)':(return_point-baseline)/30, \n",
    "                               'Amplitude base-max (V)':max_value - baseline_value, \n",
    "                               'Amplitude min-max (V)':max_value + np.absolute(min_value),\n",
    "                              'spike_category': 'up_down_up'}, index=[0])\n",
    "    \n",
    "    plot_waveform(fig_to_save, correct_chan, baseline, min_peak_time, baseline_value, return_point)\n",
    "    \n",
    "data_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_baseline_for_down_up(min_peak_time, from_start_to_min, correct_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan['y_values'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan['y_values'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan['y_values'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_baseline(max_peak_time, from_start_to_max, correct_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_chan['y_values'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_algo_for_down_up(y=correct_chan['y_values'], lag=5, threshold=3.5, influence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
