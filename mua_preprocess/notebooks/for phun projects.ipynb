{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from scipy import signal as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING IT CRASHED !!$%$#$%$%&^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kilosort_arrays(recording):\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except AssertionError:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(\n",
    "            recording))\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "\n",
    "def load_raw_data(kilosort_folder, recording, num_channels):\n",
    "    path = os.path.join(kilosort_folder, recording, recording) + '.dat'\n",
    "    temp_data = np.memmap(path, dtype=np.int16)\n",
    "    adjusted_len = int(len(temp_data) / num_channels)  # adjust for number of channels\n",
    "\n",
    "    raw_data = np.memmap(path, dtype=np.int16, shape=(adjusted_len, num_channels))\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "def choosing_spike(extracted_spikes, time_chosen):\n",
    "    Spike_chosen = (extracted_spikes - time_chosen * 30000).abs().argsort()[:1]\n",
    "    return Spike_chosen\n",
    "\n",
    "\n",
    "def load_data(recording, kilosort_folder, verbose):\n",
    "    if verbose:\n",
    "        print('\\nLoading Data:\\t{}\\n'.format(recording))\n",
    "        os.chdir(os.path.join(kilosort_folder, recording))\n",
    "        spike_clusters, spike_times, cluster_groups = load_kilosort_arrays(\n",
    "            recording)\n",
    "    return spike_clusters, spike_times, cluster_groups\n",
    "\n",
    "\n",
    "def get_good_cluster_numbers(cluster_groups_df):\n",
    "    good_clusters_df = cluster_groups_df.loc[cluster_groups_df['group'] == 'good', :]\n",
    "    return good_clusters_df['cluster_id'].values\n",
    "\n",
    "\n",
    "def band_passfilter(fs, low=None, high=None, order=None):\n",
    "    low = low / (fs / 2)\n",
    "    high = high / (fs / 2)\n",
    "    return ss.butter(N=order, Wn=(low, high), btype='pass')\n",
    "\n",
    "\n",
    "def apply_filter(array, low, high, fs, order, axis=-1):\n",
    "    b, a = band_passfilter(fs=fs, low=low, high=high, order=order)\n",
    "    return ss.filtfilt(b, a, array, axis=axis)\n",
    "\n",
    "\n",
    "def create_trace_parameters(time_span, extracted_spikes, Spike_chosen):\n",
    "    num_samples_in_trace = time_span * 30000\n",
    "    waveform_window = np.arange(int(-num_samples_in_trace / 2), int(num_samples_in_trace / 2))\n",
    "    start_index = int(extracted_spikes.iloc[Spike_chosen] + waveform_window[0])\n",
    "    end_index = int((extracted_spikes.iloc[Spike_chosen] + waveform_window[-1]) + 1)\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "def extract_highlighted_spikes(time_span, extracted_spikes, Spike_chosen):\n",
    "    num_samples_in_trace = time_span * 30000\n",
    "    waveform_window = np.arange(int(-num_samples_in_trace / 2), int(num_samples_in_trace / 2))\n",
    "    start_index = int(extracted_spikes.iloc[Spike_chosen] + waveform_window[0])\n",
    "    end_index = int((extracted_spikes.iloc[Spike_chosen] + waveform_window[-1]) + 1)\n",
    "    highlighted_spike_list = extracted_spikes[(start_index <= extracted_spikes) & (extracted_spikes <= end_index)]\n",
    "    return highlighted_spike_list\n",
    "\n",
    "\n",
    "def create_3D_matrix(num_spikes_for_averaging, extracted_spikes, data):\n",
    "    threeD_matrix = np.zeros((num_spikes_for_averaging, 240, 32))\n",
    "    waveform_window = np.arange(-120, 120)\n",
    "    for spike in np.arange(0, num_spikes_for_averaging):\n",
    "        start_index = int(extracted_spikes.iloc[spike] + waveform_window[0])\n",
    "        end_index = int((extracted_spikes.iloc[spike] + waveform_window[-1]) + 1)\n",
    "\n",
    "        waveform = data[start_index:end_index, 0:32]\n",
    "        threeD_matrix[spike, :, :] = waveform[:, :]\n",
    "    return threeD_matrix\n",
    "\n",
    "\n",
    "def extract_trace(Spike_chosen, extracted_spikes, time_span, data, chosen_channel):\n",
    "    start_index, end_index = create_trace_parameters(time_span, extracted_spikes, Spike_chosen)\n",
    "    filtered_data = apply_filter(array=data[start_index:end_index, chosen_channel], low=400, high=6000, fs=30000, order=4)\n",
    "    df_trace = pd.DataFrame({'Value': filtered_data})\n",
    "    df_trace['time'] = np.arange(start_index / 30000, end_index / 30000, 1 / 30000)\n",
    "    return df_trace\n",
    "\n",
    "\n",
    "def choose_channel(Spike_chosen, extracted_spikes, time_span, data, broken_chans, num_spikes_for_averaging):\n",
    "    start_index, end_index = create_trace_parameters(time_span, extracted_spikes, Spike_chosen)\n",
    "    temporary_df = pd.DataFrame(data[start_index:end_index])\n",
    "    if broken_chans:\n",
    "        for chan in broken_chans:\n",
    "            temporary_df.drop((chan), inplace=True, axis=1)\n",
    "\n",
    "    threeD_matrix = create_3D_matrix(num_spikes_for_averaging, extracted_spikes, data)\n",
    "\n",
    "    mean_waveform = np.mean(threeD_matrix, axis=0)\n",
    "    waveform_per_channel_df = pd.DataFrame(mean_waveform)\n",
    "    maxes = waveform_per_channel_df.apply(np.min, axis=0)\n",
    "    chosen_channel = maxes.idxmin()\n",
    "    return chosen_channel\n",
    "\n",
    "\n",
    "def spike_highlight(spike, extracted_spikes, data, chosen_channel):\n",
    "    window_for_highlight = np.arange(-30, 30)\n",
    "    start_highlight = int(spike + window_for_highlight[0])\n",
    "    end_highlight = int((spike + window_for_highlight[-1]) + 1)\n",
    "    filtered_highlight_data = apply_filter(array=data[start_highlight:end_highlight, chosen_channel], low=400, high=6000, fs=30000, order=4)\n",
    "    df_highlight = pd.DataFrame({'Value': filtered_highlight_data})\n",
    "    df_highlight['time'] = np.arange(start_highlight, end_highlight, 1)\n",
    "    df_highlight_final = pd.DataFrame({'time': df_highlight['time'] / 30000, 'Value': df_highlight['Value']})\n",
    "    return df_highlight_final\n",
    "\n",
    "\n",
    "def plot_final_data(kilosort_folder, recording, chosen_channel, chosen_cluster, highlighted_spike_list, time_chosen):\n",
    "    fig_folder =  os.path.join(kilosort_folder, recording, 'figures', 'Cluster no.' + str(chosen_cluster))\n",
    "    font = {'fontname':'Calibri'}\n",
    "    plt.ylim(-1200, 800)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=50)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(np.arange(time_chosen-5, time_chosen+7,2), np.arange(0, 12, 2.0))\n",
    "    plt.xlabel('Time [s]', **font, fontsize=70)\n",
    "    plt.ylabel('Voltage [ÂµV]', **font, fontsize=70)\n",
    "    plt.title('Slow Regular', **font, fontsize=80)\n",
    "    plt.annotate('no. of spikes: {}'.format(len(highlighted_spike_list)), xy=(time_chosen, 1500), xytext=(time_chosen, 1500), size=30)\n",
    "    mkdirs_(fig_folder)\n",
    "    if time_chosen >= 60*60: \n",
    "        figpath = os.path.join(kilosort_folder, recording, 'figures', 'Cluster no.' + str(chosen_cluster), recording + ' Cluster no.' + str(chosen_cluster) + ' After.png')\n",
    "    else:\n",
    "        figpath = os.path.join(kilosort_folder, recording, 'figures', 'Cluster no.' + str(chosen_cluster), recording + ' Cluster no.' + str(chosen_cluster) + ' Before.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figpath)\n",
    "\n",
    "\n",
    "def choose_cluster_to_plot(cluster_groups, spike_clusters, spike_times, chosen_cluster):\n",
    "    good_cluster_numbers = get_good_cluster_numbers(cluster_groups)\n",
    "    df = pd.DataFrame({'cluster': spike_clusters.flatten(), 'spike_times': spike_times.flatten()})\n",
    "    df = df.loc[df['cluster'].isin(good_cluster_numbers)]\n",
    "    cluster_to_plot = good_cluster_numbers[good_cluster_numbers == chosen_cluster][0]\n",
    "    return df, cluster_to_plot\n",
    "\n",
    "def mkdirs_(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilosort_folder=r'G:\\Rawdata\\SERT'\n",
    "recording='2018-04-12_371b'\n",
    "chosen_cluster=148\n",
    "time_span_chosen = [60, 60.5]\n",
    "num_channels=32\n",
    "broken_chans=[22]\n",
    "num_spikes_for_averaging=3000\n",
    "verbose=True\n",
    "color='#0392cf'\n",
    "operating_system='win'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data:\t2018-04-12_371b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_raw_data(kilosort_folder=kilosort_folder,\n",
    "                         recording=recording,\n",
    "                         num_channels=num_channels)\n",
    "spike_clusters, spike_times, cluster_groups = load_data(recording=recording,\n",
    "                                                            kilosort_folder=kilosort_folder,\n",
    "                                                            verbose=verbose)\n",
    "df, cluster_to_plot = choose_cluster_to_plot(cluster_groups=cluster_groups,\n",
    "                                                 spike_clusters=spike_clusters,\n",
    "                                                 spike_times=spike_times,\n",
    "                                                 chosen_cluster=chosen_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_spikes = df[df['cluster'] == cluster_to_plot]['spike_times']\n",
    "Spike_chosen = choosing_spike(extracted_spikes=extracted_spikes,\n",
    "                                  time_chosen=time_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_channel = choose_channel(Spike_chosen=Spike_chosen,\n",
    "                                    extracted_spikes=extracted_spikes,\n",
    "                                    time_span=time_span,\n",
    "                                    data=data,\n",
    "                                    broken_chans=broken_chans,\n",
    "                                    num_spikes_for_averaging=num_spikes_for_averaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trace = extract_trace(Spike_chosen=Spike_chosen,\n",
    "                             extracted_spikes=extracted_spikes,\n",
    "                             time_span=time_span,\n",
    "                             data=data,\n",
    "                             chosen_channel=chosen_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot(time_span, time_chosen, extracted_spikes, Spike_chosen, df_trace, data, chosen_channel):\n",
    "\n",
    "    data_to_plot = []\n",
    "    highlighted_spike_list = extract_highlighted_spikes(time_span=time_span,\n",
    "                                                            extracted_spikes=extracted_spikes,\n",
    "                                                            Spike_chosen=Spike_chosen)\n",
    "    trace0 = go.Scatter(\n",
    "        x = df_trace['time'],\n",
    "        y = df_trace['Value'],\n",
    "        mode = 'lines',\n",
    "        name = 'lines',\n",
    "        line = dict(\n",
    "            color = ('rgb(230, 230, 230)'),\n",
    "            width = 1)\n",
    "    )\n",
    "    data_to_plot.append(trace0)\n",
    "\n",
    "    for spike in highlighted_spike_list:  # loop over each spike in original trace. Plot in color\n",
    "        df_highlight = spike_highlight(spike=spike,\n",
    "                                           extracted_spikes=extracted_spikes,\n",
    "                                           data=data,\n",
    "                                           chosen_channel=chosen_channel)\n",
    "        trace= go.Scatter(\n",
    "        x = df_highlight['time'],\n",
    "        y = df_highlight['Value'],\n",
    "        mode = 'lines',\n",
    "        name = 'lines',\n",
    "        line = dict(\n",
    "            color = ('rgb(102, 153, 255)'),\n",
    "            width = 1))\n",
    "        data_to_plot.append(trace)\n",
    "\n",
    "    layout = go.Layout(xaxis=dict(\n",
    "            range=[time_chosen-3, time_chosen+3]), yaxis=dict(\n",
    "            range=[-1800, 1800]\n",
    "        ),\n",
    "                       showlegend=False)\n",
    "\n",
    "    fig = go.Figure(data=data_to_plot, layout=layout)\n",
    "\n",
    "    plot(fig, filename='line-mode.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly_plot(time_span=time_span, time_chosen = time_chosen, extracted_spikes=extracted_spikes, Spike_chosen=Spike_chosen, df_trace=df_trace, data=data, chosen_channel=chosen_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ops.time_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
