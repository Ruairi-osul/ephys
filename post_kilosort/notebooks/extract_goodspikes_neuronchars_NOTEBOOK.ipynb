{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rory\\Anaconda3\\lib\\site-packages\\NeuroTools\\__init__.py:125: DependencyWarning: ** interval ** package is not installed.\n",
      "To have functions using interval please install the package.\n",
      "website : http://pypi.python.org/pypi/interval/1.0.0\n",
      "\n",
      "  warnings.warn(get_import_warning(name), DependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import NeuroTools.signals as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_to_extract = ['401a_2018-04-18_16-34-20_NO_CNO']\n",
    "\n",
    "kilosort_folder = r'C:\\Users\\Rory\\raw_data\\SERT_DREADD\\dat_files'\n",
    "\n",
    "spikes_df_csv_out_folder = r'C:\\Users\\Rory\\raw_data\\SERT_DREADD\\spikes_df'\n",
    "neuron_characteristics_df_csv_out_folder = r'C:\\Users\\Rory\\raw_data\\SERT_DREADD\\neuron_characteristics'\n",
    "\n",
    "\n",
    "sampling_rate = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording_to_extract in recordings_to_extract:\n",
    "    path_to_data = '\\\\'.join([kilosort_folder, recording_to_extract])\n",
    "    os.chdir(path_to_data)\n",
    "    \n",
    "    # load kilosort data files\n",
    "    spike_clusters = np.load('spike_clusters.npy')\n",
    "    spike_times = np.load('spike_times.npy')\n",
    "    cluster_groups = pd.read_csv('cluster_groups.csv', sep='\\t')\n",
    "    \n",
    "    try:  # check data quality\n",
    "        assert np.shape(spike_times.flatten()) == np.shape(spike_clusters)\n",
    "    except:\n",
    "        AssertionError('Array lengths do not match in recording {}'.format(recording_to_extract))\n",
    "    \n",
    "    \n",
    "    # find single unit clusters\n",
    "    good_clusters_df = cluster_groups.loc[cluster_groups['group']=='good', :]\n",
    "    good_cluster_numbers = good_clusters_df['cluster_id'].values\n",
    "\n",
    "    \n",
    "    # create spikes data frame \n",
    "    labels = ['spike_cluster', 'spike_time']\n",
    "    data = [spike_clusters.flatten(), spike_times.flatten()]\n",
    "    data_dict = dict(zip(labels, data))\n",
    "    \n",
    "    df_with_bad_spikes = pd.DataFrame(data)\n",
    "    df_with_bad_spikes = df_with_bad_spikes.transpose()\n",
    "    df_with_bad_spikes.rename(columns={0:labels[0], 1:labels[1]}, inplace=True)\n",
    "    \n",
    "    # filter only rows corresponding to spikes from single units\n",
    "    good_spikes_df = df_with_bad_spikes.loc[df_with_bad_spikes['spike_cluster'].isin(good_cluster_numbers), :]\n",
    "    good_spikes_df['time'] = good_spikes_df['spike_time'].divide(sampling_rate)\n",
    "    \n",
    "    # save good spikes df to csv\n",
    "    df.to_csv('\\\\'.join([spikes_df_csv_out_folder, recording_to_extract]) + '.csv')\n",
    "    \n",
    "    \n",
    "    # extract neuron characteristics\n",
    "    all_neurons_container = {}\n",
    "    for cluster in good_cluster_numbers:\n",
    "        neuron = good_spikes_df.loc[good_spikes_df['spike_cluster'] == cluster]\n",
    "\n",
    "        spike_times = neuron['time'].values * 1000\n",
    "        t_start= spike_times[0]\n",
    "        t_stop= spike_times[-1]\n",
    "        spike_train_object = nt.SpikeTrain(spike_times,\n",
    "                                       t_start=t_start,\n",
    "                                       t_stop=t_stop)\n",
    "\n",
    "        rate = spike_train_object.mean_rate()\n",
    "        cv_isi =  spike_train_object.cv_isi()\n",
    "\n",
    "        neuron_dict = {'cluster':cluster, 'rate': rate, 'cv_isi': cv_isi}\n",
    "        all_neurons_container[cluster] = neuron_dict\n",
    "        \n",
    "    # create and savesave neuron_characteristics_df\n",
    "    df = pd.DataFrame(data=all_neurons_container)\n",
    "    df = df.transpose()\n",
    "    df = df.set_index('cluster')\n",
    "    df.to_csv('\\\\'.join([spikes_df_csv_out_folder, recording_to_extract]) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
